{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 10 Assignment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN1FrydvsWfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3daff6d6-8d8d-49ed-d76b-d05241c2b592"
      },
      "source": [
        "#Q1\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "dice=0\n",
        "for i in range(250):\n",
        "    walk = [0] \n",
        "    for x in range(100):\n",
        "        step = walk[-1] \n",
        "        dice = random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "        else:\n",
        "            step = step + random.randint(1,7)\n",
        "    print(step)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "4\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "0\n",
            "6\n",
            "0\n",
            "1\n",
            "5\n",
            "7\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "7\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "4\n",
            "0\n",
            "6\n",
            "0\n",
            "1\n",
            "0\n",
            "4\n",
            "0\n",
            "4\n",
            "5\n",
            "0\n",
            "1\n",
            "7\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "0\n",
            "1\n",
            "7\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "6\n",
            "4\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "6\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "4\n",
            "7\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "6\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "6\n",
            "0\n",
            "7\n",
            "1\n",
            "7\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "3\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "5\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "7\n",
            "3\n",
            "0\n",
            "3\n",
            "7\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "6\n",
            "5\n",
            "4\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "5\n",
            "1\n",
            "0\n",
            "4\n",
            "6\n",
            "1\n",
            "7\n",
            "5\n",
            "0\n",
            "0\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "6\n",
            "0\n",
            "3\n",
            "7\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfTiPH67sc6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "91424ba9-fc2c-464d-f147-72d604b8cebf"
      },
      "source": [
        "#Q2 Random data for multiple linear regression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n= 3\n",
        "X=[]\n",
        "for i in range(0,n):\n",
        "    X_i= scipy.stats.norm.rvs(0, 1, 100)\n",
        "    X.append(X_i)\n",
        "eps=scipy.stats.norm.rvs(0, 1, 100)\n",
        "y = 1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2])  + eps\n",
        "data_ols = {'X0': X[0],'X1':X[1],'X2':X[2] ,'Y': y }\n",
        "df = pd.DataFrame(data_ols)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0 -0.470167 -0.597878 -0.696690  1.683323\n",
            "1  1.415711  0.855473 -0.280813  1.136249\n",
            "2 -1.275481  0.199060 -1.001693 -1.302541\n",
            "3  0.644035  0.402955 -0.010345 -0.148864\n",
            "4 -0.680659 -0.533335 -0.858426  1.127564\n",
            "          X0        X1        X2         Y\n",
            "95 -0.570323 -0.578002  1.382865  1.031014\n",
            "96  0.527700  0.199085  2.039880  1.849749\n",
            "97  0.274996  0.479901 -0.385259  2.466038\n",
            "98 -1.245611 -1.496926  1.417382 -1.176532\n",
            "99  0.783529  0.946782 -1.123398  1.297033\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.043738    0.180550   -0.046810    1.013062\n",
            "std      1.068781    1.023890    1.059412    1.280860\n",
            "min     -2.537650   -3.166038   -2.406518   -1.934392\n",
            "25%     -0.683397   -0.544502   -0.806369    0.280265\n",
            "50%     -0.074823    0.284166   -0.028650    0.992689\n",
            "75%      0.612249    0.986598    0.744740    1.878675\n",
            "max      3.101444    2.059971    2.631245    4.582968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RoOOZ5es3-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "aa7fd77f-6ec1-4b94-9b69-9b428486d60e"
      },
      "source": [
        "# random data for Logistic Regression\n",
        "X = []\n",
        "n = 3\n",
        "for i in range(0,n):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "odds = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2])) /(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) ))) \n",
        "y1 = [ ]\n",
        "for i in odds:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2] ,'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0 -0.470167 -0.597878 -0.696690  1.683323\n",
            "1  1.415711  0.855473 -0.280813  1.136249\n",
            "2 -1.275481  0.199060 -1.001693 -1.302541\n",
            "3  0.644035  0.402955 -0.010345 -0.148864\n",
            "4 -0.680659 -0.533335 -0.858426  1.127564\n",
            "          X0        X1        X2         Y\n",
            "95 -0.570323 -0.578002  1.382865  1.031014\n",
            "96  0.527700  0.199085  2.039880  1.849749\n",
            "97  0.274996  0.479901 -0.385259  2.466038\n",
            "98 -1.245611 -1.496926  1.417382 -1.176532\n",
            "99  0.783529  0.946782 -1.123398  1.297033\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.043738    0.180550   -0.046810    1.013062\n",
            "std      1.068781    1.023890    1.059412    1.280860\n",
            "min     -2.537650   -3.166038   -2.406518   -1.934392\n",
            "25%     -0.683397   -0.544502   -0.806369    0.280265\n",
            "50%     -0.074823    0.284166   -0.028650    0.992689\n",
            "75%      0.612249    0.986598    0.744740    1.878675\n",
            "max      3.101444    2.059971    2.631245    4.582968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95GvMDMEs-s_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "outputId": "20d63913-23c0-46c3-9c32-1e09c2796fa5"
      },
      "source": [
        "# random data for k means clustering\n",
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0 -0.470167 -0.597878 -0.696690  1.683323\n",
            "1  1.415711  0.855473 -0.280813  1.136249\n",
            "2 -1.275481  0.199060 -1.001693 -1.302541\n",
            "3  0.644035  0.402955 -0.010345 -0.148864\n",
            "4 -0.680659 -0.533335 -0.858426  1.127564\n",
            "          X0        X1        X2         Y\n",
            "95 -0.570323 -0.578002  1.382865  1.031014\n",
            "96  0.527700  0.199085  2.039880  1.849749\n",
            "97  0.274996  0.479901 -0.385259  2.466038\n",
            "98 -1.245611 -1.496926  1.417382 -1.176532\n",
            "99  0.783529  0.946782 -1.123398  1.297033\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.043738    0.180550   -0.046810    1.013062\n",
            "std      1.068781    1.023890    1.059412    1.280860\n",
            "min     -2.537650   -3.166038   -2.406518   -1.934392\n",
            "25%     -0.683397   -0.544502   -0.806369    0.280265\n",
            "50%     -0.074823    0.284166   -0.028650    0.992689\n",
            "75%      0.612249    0.986598    0.744740    1.878675\n",
            "max      3.101444    2.059971    2.631245    4.582968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv1SBQOwthPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "019ef308-7e5a-4822-a335-f3d7ae4f6cc5"
      },
      "source": [
        "#Q3 Linear regression with gradient descent\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 150\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.15322835117997594 0.2784075461935174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5KwLT44ts8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "95d6c539-98ed-4436-d18d-1d20807747af"
      },
      "source": [
        "# logistic regression with gradient descent\n",
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.27859278666018344\n",
            "0.2784190168093606\n",
            "0.2782480300212511\n",
            "0.27807979543962735\n",
            "0.27791428289762743\n",
            "0.27775146286151003\n",
            "0.2775913063766637\n",
            "0.27743378501586985\n",
            "0.27727887082982106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ96LcNtt4kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2960c204-a688-457b-f4bc-b440cfdada3a"
      },
      "source": [
        "# LINEAR REGRESSION WITH L1 REGULARIZATION\n",
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09952771769294254 0.19593154996993165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c4lR0cjuBfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8cbd964c-d0fc-47f3-ea45-26cc4dda4423"
      },
      "source": [
        "#LINEAR REGRESSION WITH L2 REGULARIZATION\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10814146199901643 0.1957556683967352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSsVmgtIuOqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6274184e-6c5a-4a66-fcb4-f7ac677ba538"
      },
      "source": [
        "#LOGISTIC REGRESSION WITH L1 REGULARIZATION\n",
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.019601401717822098\n",
            "-0.3162125171410469\n",
            "-0.6104678850418105\n",
            "-0.902394229004092\n",
            "-1.1920180078190024\n",
            "-1.4793654147469617\n",
            "-1.7644623793537961\n",
            "-2.047334571613743\n",
            "-2.3280074079685003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--OPA2yPuVnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4fc12b60-0ea2-4e90-d2ef-6cb0e160df7c"
      },
      "source": [
        "#LOGISTIC REGRESSION WITH L2 REGULARIZATION\n",
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.27876852312562916\n",
            "0.2791094326393827\n",
            "0.2797738727028874\n",
            "0.28074430767886627\n",
            "0.28200388235427176\n",
            "0.2835363977358466\n",
            "0.2853262879441776\n",
            "0.2873585981305966\n",
            "0.28961896334690934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT01sTnXucoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "1bd53d20-cb83-44fa-a006-23e57970e269"
      },
      "source": [
        "#K-MEANS CLUSTERING ALGORITHM\n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]\n",
        "\n",
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.75397250770902\n",
            "138.92646321931022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu3D-MBKushx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LINEAR REGRESSION WITH OOPS\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) \n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "    if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQNU9bTqu6DW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LOGISTIC REGRESSION WITH OOPS\n",
        "\n",
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}